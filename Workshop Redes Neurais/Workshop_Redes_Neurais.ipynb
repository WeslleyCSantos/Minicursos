{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/W-santos/Notebooks/blob/master/Workshop_Redes_Neurais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wE86zkUApBAJ"
   },
   "source": [
    "# O que é machine learning? \n",
    "\n",
    "Machine learning é um subcampo da ciência da computação em que máquinas aprendem a realizar tarefas para as quais elas não foram programadas explicitamente, ou seja, as máquinas \"observam\" um padrão e tentam imitá-lo de uma forma que pode ser direta ou indireta.\n",
    "\n",
    "## E o que significa essa forma direta e indireta?\n",
    "\n",
    "Existem basicamente dois tipos de aprendizado de máquina, o aprendizado supervisionado e o não supervisionado. O aprendizado supervisionado é a imitação direta do padrão entre dois conjuntos de dados, de forma que está sempre tentando pegar um conjunto de entrada e transformá-lo num conjunto de saída. Este tipo de aprendizado pode ser muito poderoso e ter muitas utilizações, tais quais:\n",
    "\n",
    "* Usar os pixels de uma imagem para detectar a presença ou ausência de uma pessoa\n",
    "* Usar os filmes que você gostou para prever filmes que você gostaria\n",
    "* Usar textos de pessoas para prever se estão felizes ou tristes\n",
    "* Usar sensores de clima para prever se irá chover ou não\n",
    "* Usar um número de entrada para prever um número duas vezes maior\n",
    "\n",
    "\n",
    "# O aprendizado supervisionado transforma datasets\n",
    "\n",
    "O aprendizado supervisionado é um método para transformar um dataset em outro. Por exemplo, se tivéssemos um dataset chamado Preço das ações na segunda que salva o preço de cada ação em cada segunda pelos 10 anos passados e um dataset chamado Preços das ações na terça que salvou o preço doas ações no mesmo período, um algoritmo de aprendizado pode utilizar um para prever o outro.\n",
    "\n",
    "\n",
    "Se treinarmos com sucesso o algoritmo de aprendizado supervisionado nos 10 anos de informações que temos da segunda e terça, poderíamos prever o preço de qualquer ação de qualquer terça no futuro, dado o preço da ação na segunda anterior.\n",
    "\n",
    "\n",
    "# Aprendizado supervisionado paramétrico\n",
    "\n",
    "O aprendizados paramétrico são máquinas com um número fixo de botões (esta é a parte paramétrica), em que a parte do aprendizado se dá pelo ajuste dos botões. \n",
    "\n",
    "Os dados de entrada vem, o processo é baseado na posição dos botões e é transformado em uma predição.\n",
    "\n",
    "![alt text](https://drive.google.com/uc?export=view&id=1zPVP0SUMojLeDmdHHlgROK4HouIdENC7)\n",
    "\n",
    "\n",
    "O aprendizado é realizado girando os botões para ângulos diferentes. Se quisermos prever a probabilidade do Auto Esporte ser campeão Mundial de futebol, este modelo pegaria os dados, como por exemplo histórico de vitórias e derrotas, número médio de dedos do pé por jogador, e faria uma previsão, tal como a chance de vitória (98% na imagem). \n",
    "\n",
    "Após isso, o modelo iria observar se o Auto Esporte ganhou ou não. Depois de saber, o algoritmo de aprendizado iria atualizar a posição dos botões para fazer uma previsão melhor da próxima vez que ver um dado de entrada igual ou similar.\n",
    "\n",
    "Por exemplo, ele poderia aumentar a posição do botão de histórico de vitórias e derrotas, já que este pode ser um bom previsor da chance de ganhar e diminuir a botão de médias de dedos no pé, já que este não foi um bom previsor. É deste jeito que o aprendizado paramétrico funciona.\n",
    "\n",
    "Podemos quebrar o aprendizado supervisionado paramétrico em 3 etapas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X9aX_3FO2daq"
   },
   "source": [
    "## 1 - Previsão\n",
    "## 2 - Comparar com o resultado esperado\n",
    "## 3 - Aprender o padrão\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_o2lQ12nJfH"
   },
   "source": [
    "# Rede Neural com uma entrada e uma saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FQK8s5a-nLNr",
    "outputId": "1fb81553-930c-4f28-f8a0-15d5e47924cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "def rede_neural(entrada):\n",
    "  wt = .1\n",
    "  return entrada*wt\n",
    "\n",
    "ent = [100]\n",
    "previsao = rede_neural(ent[0])\n",
    "print(previsao)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wLvCV96unNF7"
   },
   "source": [
    "# Rede neural com várias entradas e um saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b3un5kd0nOBU",
    "outputId": "b0c088e4-eeac-48f0-e222-1cf4b475a2d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.91\n"
     ]
    }
   ],
   "source": [
    "def rede_neural(entrada):\n",
    "  wt = [0.1,0.3,0.5]\n",
    "  soma = 0\n",
    "  for i in range(3):\n",
    "    soma+=entrada[i]*wt[i]\n",
    "  return soma\n",
    "\n",
    "idades = [100,25,30]\n",
    "pesos = [90,75,54]\n",
    "alturas = [1.82,1.75,1.64]\n",
    "entrada = [idades[0],pesos[0],alturas[0]]\n",
    "previsao = rede_neural(entrada)\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9IMTVH6fnQwE"
   },
   "source": [
    "# Utilizando o numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "svhECZ9enTZV",
    "outputId": "463d454f-2e0d-4f16-862d-42dec51f5afc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.91\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def rede_neural(entrada):\n",
    "  wt = np.array([0.1,0.3,0.5])\n",
    "  return np.dot(entrada,wt)\n",
    "\n",
    "idades = np.array([100,25,30])\n",
    "pesos = np.array([90,75,54])\n",
    "alturas = np.array([1.82,1.75,1.64])\n",
    "entrada = np.array([idades[0],pesos[0],alturas[0]])\n",
    "previsao = rede_neural(entrada)\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NCWIyHgDnVIo"
   },
   "source": [
    "# Rede neural com várias entradas e várias saídas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sTU5Hn-ynVqu",
    "outputId": "ac7901c8-3db7-4793-9157-2104392cf99e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 37.91   48.274 285.46 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def rede_neural(entrada):\n",
    "  wt = np.array([[0.1,0.3,0.5],[0.2,0.3,0.7],[1,2,3]]).T\n",
    "  return entrada.dot(wt)\n",
    "\n",
    "idades = np.array([100,25,30])\n",
    "pesos = np.array([90,75,54])\n",
    "alturas = np.array([1.82,1.75,1.64])\n",
    "entrada = np.array([idades[0],pesos[0],alturas[0]])\n",
    "previsao = rede_neural(entrada)\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6mWbsaRynYdo"
   },
   "source": [
    "# Rede neural com camadas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5lerztwBnZSo",
    "outputId": "10a8c779-a8b7-404a-abf7-dd3b8211b2ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107.76599999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def rede_neural(entrada):\n",
    "  in_wt = np.array([[0.1,0.3,0.5],[0.2,0.3,0.7],[1,2,3]]).T\n",
    "  out_wt = np.array([0.7,0.5,0.2])\n",
    "  hid = entrada.dot(in_wt)\n",
    "  saida = hid.dot(out_wt)\n",
    "  return saida\n",
    "\n",
    "idades = np.array([100,25,30])\n",
    "pesos = np.array([90,75,54])\n",
    "alturas = np.array([1.82,1.75,1.64])\n",
    "entrada = np.array([idades[0],pesos[0],alturas[0]])\n",
    "previsao = rede_neural(entrada)\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uKAFbTz3ncOH"
   },
   "source": [
    "# Comparação de erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "dxucxykbndii",
    "outputId": "0051b3d8-40f7-4c27-bade-ea50e498bfb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.955199999999998\n",
      "133.05161104 27.49\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def rede_neural(entrada,saida):\n",
    "  in_wt = np.array([[0.1,0.3],[0.2,0.3]]).T\n",
    "  out_wt = np.array([0.7,0.5])\n",
    "  hid = entrada.dot(in_wt)\n",
    "  previsao = hid.dot(out_wt)\n",
    "  print(previsao)\n",
    "  return (saida- previsao)**2\n",
    "\n",
    "\n",
    "pesos = np.array([90,75,54])\n",
    "alturas = np.array([1.82,1.75,1.64])\n",
    "entrada = np.array([pesos[0],alturas[0]])\n",
    "saida = 27.49\n",
    "erro = rede_neural(entrada,saida)\n",
    "print(erro,saida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KBRVqdxjnrO9"
   },
   "source": [
    "# Estratégia do quente-frio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HI552T17nscn",
    "outputId": "7f10301d-c0e0-4958-ce16-582655ba1bcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0728 27.17\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def rede_neural(entrada,saida):\n",
    "  in_wt = np.array([[0.1,0.3],[0.2,0.3]]).T\n",
    "  out_wt = np.array([0.7,0.5])\n",
    "  learning_rate = 0.1\n",
    "  for it in range(10000):\n",
    "    hid = entrada.dot(in_wt)\n",
    "    previsao = hid.dot(out_wt)\n",
    "    erro = (saida- previsao)**2\n",
    "    \n",
    "    prev_acima = entrada.dot(in_wt+learning_rate)\n",
    "    prev_acima2 = prev_acima.dot(out_wt+learning_rate)\n",
    "    erro_acima = (prev_acima2-saida)**2\n",
    "\n",
    "    prev_abaixo= entrada.dot(in_wt-learning_rate)\n",
    "    prev_abaixo2 = prev_acima.dot(out_wt-learning_rate)\n",
    "    erro_abaixo = (prev_abaixo2-saida)**2\n",
    "\n",
    "    if erro_abaixo < erro_acima:\n",
    "      in_wt -= learning_rate\n",
    "      out_wt -= learning_rate\n",
    "    else:\n",
    "      in_wt += learning_rate\n",
    "      out_wt += learning_rate\n",
    "  return previsao\n",
    "\n",
    "pesos = np.array([90,75,54])\n",
    "alturas = np.array([1.82,1.75,1.64])\n",
    "entrada = np.array([alturas[0],pesos[0]])\n",
    "saida = 27.17\n",
    "previsao = rede_neural(entrada,saida)\n",
    "print(previsao,saida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "23xJ4aj2nuS-"
   },
   "source": [
    "#Método do gradiente descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YXTzSeB8nwBV",
    "outputId": "b4f4e2d6-0063-4b18-d018-bd9020508d1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3025]\n",
      "[0.28756406]\n",
      "[0.27336559]\n",
      "[0.25986816]\n",
      "[0.24703717]\n",
      "[0.23483971]\n",
      "[0.2232445]\n",
      "[0.2122218]\n",
      "[0.20174335]\n",
      "[0.19178227]\n",
      "[0.18231302]\n",
      "[0.17331132]\n",
      "[0.16475407]\n",
      "[0.15661934]\n",
      "[0.14888626]\n",
      "[0.141535]\n",
      "[0.13454671]\n",
      "[0.12790347]\n",
      "[0.12158823]\n",
      "[0.11558481]\n",
      "[0.10987781]\n",
      "[0.1044526]\n",
      "[0.09929525]\n",
      "[0.09439255]\n",
      "[0.08973191]\n",
      "[0.0853014]\n",
      "[0.08108964]\n",
      "[0.07708584]\n",
      "[0.07327973]\n",
      "[0.06966154]\n",
      "[0.066222]\n",
      "[0.06295229]\n",
      "[0.05984402]\n",
      "[0.05688922]\n",
      "[0.05408032]\n",
      "[0.0514101]\n",
      "[0.04887173]\n",
      "[0.04645869]\n",
      "[0.04416479]\n",
      "[0.04198415]\n",
      "[0.03991119]\n",
      "[0.03794057]\n",
      "[0.03606726]\n",
      "[0.03428643]\n",
      "[0.03259354]\n",
      "[0.03098424]\n",
      "[0.02945439]\n",
      "[0.02800008]\n",
      "[0.02661757]\n",
      "[0.02530333]\n",
      "[0.02405398]\n",
      "[0.02286631]\n",
      "[0.02173729]\n",
      "[0.02066401]\n",
      "[0.01964373]\n",
      "[0.01867382]\n",
      "[0.0177518]\n",
      "[0.0168753]\n",
      "[0.01604208]\n",
      "[0.01525001]\n",
      "[0.01449704]\n",
      "[0.01378125]\n",
      "[0.0131008]\n",
      "[0.01245395]\n",
      "[0.01183903]\n",
      "[0.01125448]\n",
      "[0.01069879]\n",
      "[0.01017054]\n",
      "[0.00966837]\n",
      "[0.00919099]\n",
      "[0.00873719]\n",
      "[0.00830579]\n",
      "[0.00789569]\n",
      "[0.00750584]\n",
      "[0.00713524]\n",
      "[0.00678294]\n",
      "[0.00644803]\n",
      "[0.00612966]\n",
      "[0.00582701]\n",
      "[0.0055393]\n",
      "[0.00526579]\n",
      "[0.0050058]\n",
      "[0.00475863]\n",
      "[0.00452368]\n",
      "[0.00430032]\n",
      "[0.00408799]\n",
      "[0.00388615]\n",
      "[0.00369427]\n",
      "[0.00351186]\n",
      "[0.00333847]\n",
      "[0.00317363]\n",
      "[0.00301693]\n",
      "[0.00286797]\n",
      "[0.00272636]\n",
      "[0.00259175]\n",
      "[0.00246378]\n",
      "[0.00234213]\n",
      "[0.00222649]\n",
      "[0.00211656]\n",
      "[0.00201205]\n",
      "[0.00191271]\n",
      "[0.00181827]\n",
      "[0.00172849]\n",
      "[0.00164315]\n",
      "[0.00156202]\n",
      "[0.00148489]\n",
      "[0.00141157]\n",
      "[0.00134188]\n",
      "[0.00127562]\n",
      "[0.00121264]\n",
      "[0.00115277]\n",
      "[0.00109585]\n",
      "[0.00104174]\n",
      "[0.0009903]\n",
      "[0.00094141]\n",
      "[0.00089493]\n",
      "[0.00085074]\n",
      "[0.00080873]\n",
      "[0.0007688]\n",
      "[0.00073084]\n",
      "[0.00069476]\n",
      "[0.00066045]\n",
      "[0.00062784]\n",
      "[0.00059684]\n",
      "[0.00056737]\n",
      "[0.00053936]\n",
      "[0.00051273]\n",
      "[0.00048741]\n",
      "[0.00046335]\n",
      "[0.00044047]\n",
      "[0.00041872]\n",
      "[0.00039805]\n",
      "[0.00037839]\n",
      "[0.00035971]\n",
      "[0.00034195]\n",
      "[0.00032507]\n",
      "[0.00030902]\n",
      "[0.00029376]\n",
      "[0.00027925]\n",
      "[0.00026547]\n",
      "[0.00025236]\n",
      "[0.0002399]\n",
      "[0.00022805]\n",
      "[0.00021679]\n",
      "[0.00020609]\n",
      "[0.00019591]\n",
      "[0.00018624]\n",
      "[0.00017704]\n",
      "[0.0001683]\n",
      "[0.00015999]\n",
      "[0.00015209]\n",
      "[0.00014458]\n",
      "[0.00013744]\n",
      "[0.00013066]\n",
      "[0.00012421]\n",
      "[0.00011807]\n",
      "[0.00011224]\n",
      "[0.0001067]\n",
      "[0.00010143]\n",
      "[9.64257823e-05]\n",
      "[9.16647593e-05]\n",
      "[8.71388118e-05]\n",
      "[8.2836333e-05]\n",
      "[7.87462891e-05]\n",
      "[7.4858191e-05]\n",
      "[7.11620679e-05]\n",
      "[6.76484408e-05]\n",
      "[6.4308299e-05]\n",
      "[6.11330767e-05]\n",
      "[5.81146311e-05]\n",
      "[5.52452212e-05]\n",
      "[5.25174884e-05]\n",
      "[4.99244374e-05]\n",
      "[4.74594183e-05]\n",
      "[4.51161095e-05]\n",
      "[4.28885016e-05]\n",
      "[4.07708818e-05]\n",
      "[3.87578195e-05]\n",
      "[3.68441522e-05]\n",
      "[3.50249722e-05]\n",
      "[3.32956142e-05]\n",
      "[3.16516432e-05]\n",
      "[3.00888433e-05]\n",
      "[2.86032067e-05]\n",
      "[2.71909234e-05]\n",
      "[2.58483715e-05]\n",
      "[2.45721082e-05]\n",
      "[2.33588603e-05]\n",
      "[2.22055166e-05]\n",
      "[2.11091192e-05]\n",
      "[2.00668565e-05]\n",
      "[1.90760554e-05]\n",
      "[1.81341752e-05]\n",
      "[1.72388003e-05]\n",
      "[1.63876345e-05]\n",
      "[1.55784951e-05]\n",
      "[1.48093069e-05]\n",
      "[1.40780974e-05]\n",
      "[1.33829913e-05]\n",
      "[1.27222061e-05]\n",
      "[1.20940472e-05]\n",
      "[1.14969036e-05]\n",
      "[1.0929244e-05]\n",
      "[1.03896126e-05]\n",
      "[9.87662544e-06]\n",
      "[9.38896706e-06]\n",
      "[8.92538681e-06]\n",
      "[8.48469584e-06]\n",
      "[8.06576398e-06]\n",
      "[7.66751688e-06]\n",
      "[7.28893324e-06]\n",
      "[6.92904216e-06]\n",
      "[6.5869207e-06]\n",
      "[6.26169149e-06]\n",
      "[5.95252048e-06]\n",
      "[5.65861478e-06]\n",
      "[5.37922067e-06]\n",
      "[5.11362165e-06]\n",
      "[4.86113658e-06]\n",
      "[4.62111796e-06]\n",
      "[4.39295026e-06]\n",
      "[4.17604835e-06]\n",
      "[3.96985596e-06]\n",
      "[3.77384432e-06]\n",
      "[3.58751076e-06]\n",
      "[3.41037741e-06]\n",
      "[3.24199003e-06]\n",
      "[3.08191677e-06]\n",
      "[2.92974713e-06]\n",
      "[2.78509087e-06]\n",
      "[2.647577e-06]\n",
      "[2.51685289e-06]\n",
      "[2.39258328e-06]\n",
      "[2.27444948e-06]\n",
      "[2.16214854e-06]\n",
      "[2.05539245e-06]\n",
      "[1.95390745e-06]\n",
      "[1.85743327e-06]\n",
      "[1.7657225e-06]\n",
      "[1.67853995e-06]\n",
      "[1.59566204e-06]\n",
      "[1.51687623e-06]\n",
      "[1.44198047e-06]\n",
      "[1.37078268e-06]\n",
      "[1.30310029e-06]\n",
      "[1.23875971e-06]\n",
      "[1.17759595e-06]\n",
      "[1.11945215e-06]\n",
      "[1.0641792e-06]\n",
      "[1.01163535e-06]\n",
      "[9.61685855e-07]\n",
      "[9.14202616e-07]\n",
      "[8.69063862e-07]\n",
      "[8.26153834e-07]\n",
      "[7.85362488e-07]\n",
      "[7.46585215e-07]\n",
      "[7.0972257e-07]\n",
      "[6.74680018e-07]\n",
      "[6.41367692e-07]\n",
      "[6.09700163e-07]\n",
      "[5.79596217e-07]\n",
      "[5.50978654e-07]\n",
      "[5.23774083e-07]\n",
      "[4.97912737e-07]\n",
      "[4.73328296e-07]\n",
      "[4.49957711e-07]\n",
      "[4.27741049e-07]\n",
      "[4.06621335e-07]\n",
      "[3.86544407e-07]\n",
      "[3.67458777e-07]\n",
      "[3.493155e-07]\n",
      "[3.32068047e-07]\n",
      "[3.15672187e-07]\n",
      "[3.00085873e-07]\n",
      "[2.85269133e-07]\n",
      "[2.71183969e-07]\n",
      "[2.57794261e-07]\n",
      "[2.45065669e-07]\n",
      "[2.32965552e-07]\n",
      "[2.21462878e-07]\n",
      "[2.10528148e-07]\n",
      "[2.00133321e-07]\n",
      "[1.90251738e-07]\n",
      "[1.80858058e-07]\n",
      "[1.71928192e-07]\n",
      "[1.63439237e-07]\n",
      "[1.55369425e-07]\n",
      "[1.4769806e-07]\n",
      "[1.40405468e-07]\n",
      "[1.33472948e-07]\n",
      "[1.26882721e-07]\n",
      "[1.20617887e-07]\n",
      "[1.14662379e-07]\n",
      "[1.09000924e-07]\n",
      "[1.03619003e-07]\n",
      "[9.85028148e-08]\n",
      "[9.36392383e-08]\n",
      "[8.9015801e-08]\n",
      "[8.46206458e-08]\n",
      "[8.04425014e-08]\n",
      "[7.64706529e-08]\n",
      "[7.26949144e-08]\n",
      "[6.9105603e-08]\n",
      "[6.56935139e-08]\n",
      "[6.24498966e-08]\n",
      "[5.9366433e-08]\n",
      "[5.64352153e-08]\n",
      "[5.36487266e-08]\n",
      "[5.09998207e-08]\n",
      "[4.84817046e-08]\n",
      "[4.60879204e-08]\n",
      "[4.38123293e-08]\n",
      "[4.16490956e-08]\n",
      "[3.95926715e-08]\n",
      "[3.76377833e-08]\n",
      "[3.57794178e-08]\n",
      "[3.4012809e-08]\n",
      "[3.23334266e-08]\n",
      "[3.07369636e-08]\n",
      "[2.92193261e-08]\n",
      "[2.77766218e-08]\n",
      "[2.64051511e-08]\n",
      "[2.51013968e-08]\n",
      "[2.38620153e-08]\n",
      "[2.26838283e-08]\n",
      "[2.15638143e-08]\n",
      "[2.0499101e-08]\n",
      "[1.94869579e-08]\n",
      "[1.85247893e-08]\n",
      "[1.76101278e-08]\n",
      "[1.67406278e-08]\n",
      "[1.59140593e-08]\n",
      "[1.51283026e-08]\n",
      "[1.43813427e-08]\n",
      "[1.36712639e-08]\n",
      "[1.29962452e-08]\n",
      "[1.23545556e-08]\n",
      "[1.17445494e-08]\n",
      "[1.11646623e-08]\n",
      "[1.06134071e-08]\n",
      "[1.00893701e-08]\n",
      "[9.59120747e-09]\n",
      "[9.1176416e-09]\n",
      "[8.66745805e-09]\n",
      "[8.23950231e-09]\n",
      "[7.83267688e-09]\n",
      "[7.44593846e-09]\n",
      "[7.07829525e-09]\n",
      "[6.72880442e-09]\n",
      "[6.3965697e-09]\n",
      "[6.08073907e-09]\n",
      "[5.78050258e-09]\n",
      "[5.49509027e-09]\n",
      "[5.22377018e-09]\n",
      "[4.96584653e-09]\n",
      "[4.72065786e-09]\n",
      "[4.48757538e-09]\n",
      "[4.26600134e-09]\n",
      "[4.05536753e-09]\n",
      "[3.85513375e-09]\n",
      "[3.66478653e-09]\n",
      "[3.48383769e-09]\n",
      "[3.3118232e-09]\n",
      "[3.14830193e-09]\n",
      "[2.99285453e-09]\n",
      "[2.84508233e-09]\n",
      "[2.70460639e-09]\n",
      "[2.57106645e-09]\n",
      "[2.44412005e-09]\n",
      "[2.32344162e-09]\n",
      "[2.20872169e-09]\n",
      "[2.09966606e-09]\n",
      "[1.99599504e-09]\n",
      "[1.89744279e-09]\n",
      "[1.80375655e-09]\n",
      "[1.71469607e-09]\n",
      "[1.63003295e-09]\n",
      "[1.54955008e-09]\n",
      "[1.47304104e-09]\n",
      "[1.40030964e-09]\n",
      "[1.33116935e-09]\n",
      "[1.26544286e-09]\n",
      "[1.20296162e-09]\n",
      "[1.14356539e-09]\n",
      "[1.08710185e-09]\n",
      "[1.0334262e-09]\n",
      "[9.82400779e-10]\n",
      "[9.33894741e-10]\n",
      "[8.87783688e-10]\n",
      "[8.43949368e-10]\n",
      "[8.02279368e-10]\n",
      "[7.62666824e-10]\n",
      "[7.2501015e-10]\n",
      "[6.89212774e-10]\n",
      "[6.55182893e-10]\n",
      "[6.22833238e-10]\n",
      "[5.92080847e-10]\n",
      "[5.62846855e-10]\n",
      "[5.35056291e-10]\n",
      "[5.08637887e-10]\n",
      "[4.83523891e-10]\n",
      "[4.59649899e-10]\n",
      "[4.36954685e-10]\n",
      "[4.15380048e-10]\n",
      "[3.94870658e-10]\n",
      "[3.75373919e-10]\n",
      "[3.56839832e-10]\n",
      "[3.39220865e-10]\n",
      "[3.22471835e-10]\n",
      "[3.06549788e-10]\n",
      "[2.91413892e-10]\n",
      "[2.77025331e-10]\n",
      "[2.63347206e-10]\n",
      "[2.50344437e-10]\n",
      "[2.37983681e-10]\n",
      "[2.26233237e-10]\n",
      "[2.15062971e-10]\n",
      "[2.04444236e-10]\n",
      "[1.94349802e-10]\n",
      "[1.84753781e-10]\n",
      "[1.75631563e-10]\n",
      "[1.66959754e-10]\n",
      "[1.58716117e-10]\n",
      "[1.50879508e-10]\n",
      "[1.43429833e-10]\n",
      "[1.36347985e-10]\n",
      "[1.29615803e-10]\n",
      "[1.23216023e-10]\n",
      "[1.17132231e-10]\n",
      "[1.11348828e-10]\n",
      "[1.05850979e-10]\n",
      "[1.00624587e-10]\n",
      "[9.56562481e-11]\n",
      "[9.09332208e-11]\n",
      "[8.6443393e-11]\n",
      "[8.21752505e-11]\n",
      "[7.81178475e-11]\n",
      "[7.42607788e-11]\n",
      "[7.05941528e-11]\n",
      "[6.71085665e-11]\n",
      "[6.37950811e-11]\n",
      "[6.06451989e-11]\n",
      "[5.76508422e-11]\n",
      "[5.48043319e-11]\n",
      "[5.2098368e-11]\n",
      "[4.95260111e-11]\n",
      "[4.70806643e-11]\n",
      "[4.47560565e-11]\n",
      "[4.25462262e-11]\n",
      "[4.04455063e-11]\n",
      "[3.84485094e-11]\n",
      "[3.65501143e-11]\n",
      "[3.47454524e-11]\n",
      "[3.30298957e-11]\n",
      "[3.13990446e-11]\n",
      "[2.98487167e-11]\n",
      "[2.83749364e-11]\n",
      "[2.69739239e-11]\n",
      "[2.56420864e-11]\n",
      "[2.43760084e-11]\n",
      "[2.3172443e-11]\n",
      "[2.20283036e-11]\n",
      "[2.09406561e-11]\n",
      "[1.99067112e-11]\n",
      "[1.89238173e-11]\n",
      "[1.79894539e-11]\n",
      "[1.71012246e-11]\n",
      "[1.62568516e-11]\n",
      "[1.54541696e-11]\n",
      "[1.46911199e-11]\n",
      "[1.39657459e-11]\n",
      "[1.32761872e-11]\n",
      "[1.26206754e-11]\n",
      "[1.19975296e-11]\n",
      "[1.14051516e-11]\n",
      "[1.08420222e-11]\n",
      "[1.03066974e-11]\n",
      "[9.79780418e-12]\n",
      "[9.3140376e-12]\n",
      "[8.85415699e-12]\n",
      "[8.41698299e-12]\n",
      "[8.00139446e-12]\n",
      "[7.6063256e-12]\n",
      "[7.23076328e-12]\n",
      "[6.87374434e-12]\n",
      "[6.53435321e-12]\n",
      "[6.21171952e-12]\n",
      "[5.90501587e-12]\n",
      "[5.61345571e-12]\n",
      "[5.33629134e-12]\n",
      "[5.07281195e-12]\n",
      "[4.82234186e-12]\n",
      "[4.58423873e-12]\n",
      "[4.35789195e-12]\n",
      "[4.14272103e-12]\n",
      "[3.93817418e-12]\n",
      "[3.74372683e-12]\n",
      "[3.55888032e-12]\n",
      "[3.3831606e-12]\n",
      "[3.21611705e-12]\n",
      "[0.79999821] 0.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def rede_neural(entrada,saida):\n",
    "  in_wt = np.array([0.5])\n",
    "  alpha = 0.1\n",
    "  for it in range(500):\n",
    "    previsao = entrada.dot(in_wt)\n",
    "    erro = (saida- previsao)**2\n",
    "    derivada = entrada * (previsao-saida)\n",
    "    print(erro)\n",
    "    in_wt = in_wt - (alpha * derivada)\n",
    "    \n",
    "\n",
    "   \n",
    "  return previsao\n",
    "\n",
    "\n",
    "entrada = np.array(0.5)\n",
    "saida = 0.8\n",
    "previsao = rede_neural(entrada,saida)\n",
    "print(previsao,saida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UvXTP4Zqbd0Z"
   },
   "source": [
    "# Abstração do gradiente descente para múltiplas entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "id": "GTCICZGUNOUK",
    "outputId": "599af1bd-67c0-49bc-908d-56a060e2b787"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1882 0.3176 0.047 ]\n",
      "[1.85407838 2.53877117 2.82346396]\n",
      "[1.86394126 2.55192168 2.8399021 ]\n",
      "[1.86399965 2.55199954 2.83999942]\n",
      "[1.864 2.552 2.84 ]\n",
      "29.99999999977488\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def rede_neural(entrada,saida):\n",
    "  wt = np.array([.1,.2,-.1])\n",
    "  alpha = 0.001\n",
    "  for i in range(500):\n",
    "    pred = entrada.dot(wt)\n",
    "    erro = (pred-saida)**2\n",
    "    delta = pred-saida\n",
    "    delta_wt = delta*entrada\n",
    "    wt -= alpha * delta_wt\n",
    "    if i % 100 == 0:\n",
    "      print(wt)\n",
    "  return pred\n",
    "\n",
    "\n",
    "entradas = np.array([3,4,5])\n",
    "saida = 30\n",
    "print(rede_neural(entradas,saida))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YO3oRSb9jHo-"
   },
   "source": [
    "# E se congelarmos um dos pesos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "E8uQkhveiQUB",
    "outputId": "0468f2ce-a4e6-40f3-af17-08f1eee76955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1882  0.3176 -0.1   ]\n",
      "[ 3.35447643  4.5393019  -0.1       ]\n",
      "[ 3.60625015  4.8750002  -0.1       ]\n",
      "[ 3.62627051  4.90169401 -0.1       ]\n",
      "[ 3.62786248  4.90381663 -0.1       ]\n",
      "[ 3.62798906  4.90398542 -0.1       ]\n",
      "[ 3.62799913  4.90399884 -0.1       ]\n",
      "[ 3.62799993  4.90399991 -0.1       ]\n",
      "[ 3.62799999  4.90399999 -0.1       ]\n",
      "[ 3.628  4.904 -0.1  ]\n",
      "29.999999999695248\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def rede_neural(entrada,saida):\n",
    "  wt = np.array([.1,.2,-.1])\n",
    "  alpha = 0.001\n",
    "  for i in range(1000):\n",
    "    pred = entrada.dot(wt)\n",
    "    erro = (pred-saida)**2\n",
    "    delta = pred-saida\n",
    "    delta_wt = delta*entrada\n",
    "    delta_wt[2] = 0\n",
    "    wt -= alpha * delta_wt\n",
    "    if i % 100 == 0:\n",
    "      print(wt)\n",
    "\n",
    "    \n",
    "  return pred\n",
    "\n",
    "\n",
    "entradas = np.array([3,4,5])\n",
    "saida = 30\n",
    "print(rede_neural(entradas,saida))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EWHv5eWojWnm"
   },
   "source": [
    "# Gradiente descendente para uma rede neural genérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NLHCdAfzjP3O",
    "outputId": "b0e0179a-b503-423b-86eb-ce215da1555d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99999995e-01 1.81516246e-10 1.48159263e-13]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def rede_neural(entrada,saida):\n",
    "  wt = np.array([[.1,.2,-.1],[.5,.7,.8],[.2,.3,.4]]).T\n",
    "  alpha = 0.001\n",
    "  for i in range(500):\n",
    "\n",
    "    pred = entrada.dot(wt)\n",
    "    erro = (pred-saida)**2\n",
    "    delta = pred-saida\n",
    "    delta_wt = delta*entrada\n",
    "    wt -= alpha * delta_wt\n",
    "    \n",
    "  return pred\n",
    "\n",
    "\n",
    "entradas = np.array([3,4,5])\n",
    "saida = [1,0,0]\n",
    "print (rede_neural(entradas,saida))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ff-KpQ10r3iP"
   },
   "source": [
    "# O que os pesos aprendem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sO73GsGFpDF1"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JPvwM0jZsDKG"
   },
   "outputs": [],
   "source": [
    "data,target = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "vOZjPL3LsZ98",
    "outputId": "e162927f-ada6-4e4e-81e9-1dcedb5b24ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "target = target.reshape(-1,1)\n",
    "y = enc.fit_transform(target).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "5X0ZEOHbsbXF",
    "outputId": "4acdc146-33bc-4425-8641-47dbaa3de723"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndCABig4k8G9NdaTobZR9oAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.gray()\n",
    "plt.matshow(np.resize(data[340],(8,8))) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "YQXpiUIT61Vu",
    "outputId": "3b27a2b5-49d7-4d21-d9ec-9f00ba52c246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.77635684e-15 -1.77635684e-15  1.00000000e+00  3.10862447e-15\n",
      "  0.00000000e+00 -2.22044605e-16  8.88178420e-16 -4.44089210e-16\n",
      "  1.05471187e-15 -2.66453526e-15]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def rede_neural(entrada,saida):\n",
    "  wt = np.random.random((64,10))\n",
    "  alpha = 0.0001\n",
    "  for i in range(1000):\n",
    "    pred = entrada.dot(wt)\n",
    "    erro = (pred-saida)**2\n",
    "    delta = pred-saida\n",
    "    for j in range(len(entrada)):\n",
    "      delta_wt = delta*entrada[j]\n",
    "      wt[j] -= alpha * delta_wt\n",
    "      \n",
    "    \n",
    "  return pred,wt\n",
    "\n",
    "\n",
    "entrada = data[340]\n",
    "saida = y[340]\n",
    "pred,wt = rede_neural(entrada,saida)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bpQjDRESAVFU"
   },
   "outputs": [],
   "source": [
    "pesos = wt.reshape((10,8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "BtGLWJ_9NJUf",
    "outputId": "0820fe3f-035b-4c43-f9d1-08b5b26ed351"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n24oOoACKDiRA0YEEKDqQAEUHEvgPZUOvoCjA658AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.gray()\n",
    "plt.matshow(np.resize(data[340],(8,8)) * pesos[2]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UF9zQ10SQMli"
   },
   "source": [
    "#Testando com o dataset mnist original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "colab_type": "code",
    "id": "CchhKWt3DbMG",
    "outputId": "b95d0e9d-42cb-4205-fdd8-65a6f41503cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "kUABbcxPEXe6",
    "outputId": "19fc9cef-8c9c-4bde-956f-8c0a4332a61d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.gray()\n",
    "plt.matshow(np.resize(x_train[1],(28,28))) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "a_XljZs6EdBd",
    "outputId": "41f28a21-a22d-47a8-b282-31926d2152d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "[ 1.00000000e+00  0.00000000e+00  7.10542736e-14  1.36779477e-13\n",
      "  1.19015908e-13  0.00000000e+00  1.24344979e-14 -8.52651283e-14\n",
      "  7.28306304e-14  9.94759830e-14]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def rede_neural(entrada,saida):\n",
    "  wt = np.random.random((28*28,10))\n",
    "  alpha = 0.0000001\n",
    "  print(len(entrada))\n",
    "  for i in range(50):\n",
    "    pred = entrada.dot(wt)\n",
    "    erro = (pred-saida)**2\n",
    "    delta = pred-saida\n",
    "    for j in range(len(entrada)):\n",
    "      delta_wt = delta*entrada[j]\n",
    "      wt[j] -= alpha * delta_wt\n",
    "      \n",
    "    \n",
    "  return pred,wt\n",
    "\n",
    "\n",
    "entrada = x_train[1].reshape(28*28,)\n",
    "saida = np.array([1,0,0,0,0,0,0,0,0,0])\n",
    "pred,wt = rede_neural(entrada,saida)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "alCDyb6zEnNv"
   },
   "outputs": [],
   "source": [
    "pesos = wt.reshape((10,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dC5MKWXhEoVy",
    "outputId": "a252b4af-b5b3-42d0-ed6e-5d88e5cea81f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saida.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "Iogt2raMIJkR",
    "outputId": "935843fd-ecde-4748-e384-514f121b770b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAPqklEQVR4nO3db2xVdZ7H8c/XaYlUIIDMYEGUFYs6\nGgXTmA1jjJvJTlxFBRONPhjZOAk8GKMY/6zywD8PTIwZ/2xC1IDKsEbdGP9riDuGmIBESRFQgaoV\nhSxQQTSmDlXkwncf9DDbcdrfaXtv7znl+34lpLfnc+v9epRPz7n3d881dxeAuI4regAAxaIEgOAo\nASA4SgAIjhIAgqMEgOAKKQEzu8TMPjWzz83sziJmSDGzHWb2sZltNrMNJZjnaTPbZ2Zbem2baGZv\nm1lH9nVCyea718x2Z/tws5ldWuB808zsHTPbZmZbzezmbHsp9mFivrrsQ6v3OgEz+4WkzyT9q6Rd\nktokXefu2+o6SIKZ7ZDU6u77i55FkszsIkl/lfRf7n5Otu1BSd+6+wNZkU5w9/8o0Xz3Svqru/+p\niJl6M7NmSc3uvtHMxkr6QNI8Sf+uEuzDxHzXqA77sIgjgQskfe7uX7j7T5L+W9KVBcwxYrj7Gknf\n/mzzlZJWZrdXqud/mkL0M19puHunu2/Mbn8vqV3SVJVkHybmq4siSmCqpP/t9f0u1fFfeIBc0l/M\n7AMzW1j0MP2Y7O6d2e2vJE0ucph+3GhmH2WnC4WdrvRmZtMlzZa0XiXchz+bT6rDPuSJwb5d6O7n\nS/o3SX/MDndLy3vO6cq2/vtxSTMkzZLUKemhYseRzGyMpJckLXb3rt5ZGfZhH/PVZR8WUQK7JU3r\n9f3J2bbScPfd2dd9kl5RzylM2ezNziWPnlPuK3iev+Pue939sLsfkbRcBe9DM2tUz1+wZ9395Wxz\nafZhX/PVax8WUQJtklrM7J/MbJSkayW9XsAcfTKzE7InZ2RmJ0j6naQt6Z8qxOuSFmS3F0h6rcBZ\n/sHRv1yZ+SpwH5qZSXpKUru7P9wrKsU+7G++eu3Dur86IEnZSx2PSvqFpKfd/f66D9EPMztNPb/9\nJalB0nNFz2dmz0u6WNIkSXsl3SPpVUkvSDpF0k5J17h7IU/O9TPfxeo5jHVJOyQt6nX+Xe/5LpS0\nVtLHko5km5eo57y78H2YmO861WEfFlICAMqDJwaB4CgBIDhKAAiOEgCCowSA4AotgRIvyZXEfNUq\n83xlnk2q73xFHwmU+j+EmK9aZZ6vzLNJdZyv6BIAULCqFguZ2SWS/lM9K/+edPcHUvdvaGjwUaNG\n/e37SqWihoaGIT/+cGO+6pR5vjLPJtV+vp9++kmVSsX6yoZcAkO5OEhTU5O3tLQM6fEADF1HR4e6\nu7v7LIFqTge4OAhwDKimBEbCxUEA5Bj2k6LspY6FktTY2DjcDwdgkKo5EhjQxUHcfZm7t7p7a5mf\niAGiqqYESn1xEAADM+Rfze5eMbMbJf2P/v/iIFtrNhmAuqjq+NzdV0laVaNZABSAFYNAcJQAEBwl\nAARHCQDBUQJAcJQAEBwlAARHCQDBUQJAcJQAEBwlAARHCQDBUQJAcJQAEBwlAARHCQDBUQJAcJQA\nEBwlAARHCQDBUQJAcJQAEBwfCYSamTFjRjKfM2dOMl+/fn0yb25uTuZtbW3JvLu7O5lHxZEAEBwl\nAARHCQDBUQJAcJQAEBwlAARHCQDBsU4AAzZt2rRkXqlUkvnnn3+ezCdOnJjM3T2ZX3/99cn8iSee\nSOZRVVUCZrZD0veSDkuquHtrLYYCUD+1OBL4F3ffX4N/DoAC8JwAEFy1JeCS/mJmH5jZwloMBKC+\nqj0duNDdd5vZryS9bWafuPua3nfIymGhJDU2Nlb5cABqraojAXffnX3dJ+kVSRf0cZ9l7t7q7q0N\nDbwYAZTNkEvAzE4ws7FHb0v6naQttRoMQH1U86t5sqRXzOzoP+c5d3+rJlOhEFOmTEnmM2fOTObT\np09P5rNnz07m77//fjLv6upK5ps2bUrmo0ePTuYHDx5M5keOHEnmI9WQS8Ddv5B0Xg1nAVAAXiIE\ngqMEgOAoASA4SgAIjhIAgqMEgOBYwncMyVuROW7cuGS+YMGCZL5/f/rNopdffnkyb29vT+bjx49P\n5i+++GIyv//++5P5aaedlsw//PDDZL5t27ZkPlJxJAAERwkAwVECQHCUABAcJQAERwkAwVECQHCs\nEziGLF68OJnv2rUrmb/55pvJfM+ePcn8iy++SOZ51xOYP39+Ml+1alUyX7NmTTK/4447kvmKFSuS\nOesEAByTKAEgOEoACI4SAIKjBIDgKAEgOEoACI51AiPImWeemczzrot/+PDhZJ53vYDbb789mT/y\nyCPJ/IYbbkjmee/nz/v3y1sHccUVVyTzyy67LJkfqzgSAIKjBIDgKAEgOEoACI4SAIKjBIDgKAEg\nOHP3uj1YU1OTt7S01O3xRprp06cn87lz5ybzzs7OZH7GGWck87zrAbz22mvJfMqUKcn8wIEDybyr\nqyuZd3d3J/M8eZ+r8MYbbyTzvPkqlcqgZ6qXjo4OdXd3W19Z7pGAmT1tZvvMbEuvbRPN7G0z68i+\nTqjlwADqZyCnA3+WdMnPtt0pabW7t0hanX0PYATKLQF3XyPp259tvlLSyuz2SknzajwXgDoZ6hOD\nk9396AnoV5Im12geAHVW9RuI3N3NrN9nF81soaSFktTY2FjtwwGosaEeCew1s2ZJyr7u6++O7r7M\n3VvdvTXvU3MB1N9QS+B1SUdfb1kgKf3aEYDSyv3VbGbPS7pY0iQz2yXpHkkPSHrBzP4gaaeka4Zz\nyGPFiSeemMz37ev3gEqS9PXXXyfzRYsWJfP77rsvmeetE/jhhx+S+fbt25N50d56661kfuuttybz\n445L/8686667Bj1TGeSWgLtf10/02xrPAqAALBsGgqMEgOAoASA4SgAIjhIAgqMEgOBYwldDecui\nb7vttmS+du3aZD5vXvp9WjfddFMy37FjRzIfNWpUMh/pnnvuuWR+7bXXJvOpU6fWcpzS4EgACI4S\nAIKjBIDgKAEgOEoACI4SAIKjBIDgWCdQQxMmpK+8nvd+/bx1AHnXA/jkk0+SeZ4ff/yxqp8vu88+\n+yyZ33ln+qLZY8aMSeZ513MoK44EgOAoASA4SgAIjhIAgqMEgOAoASA4SgAIjnUCNdTa2prM897P\n39LSksyrXQcQ3erVq5P53Llzk/m6detqOU5pcCQABEcJAMFRAkBwlAAQHCUABEcJAMFRAkBwrBMY\nhIaG9O46/vjjk/nGjRuT+aFDhwY9Ewbu6quvTuZLly5N5uPGjavlOKWReyRgZk+b2T4z29Jr271m\nttvMNmd/Lh3eMQEMl4GcDvxZ0iV9bH/E3Wdlf1bVdiwA9ZJbAu6+RtK3dZgFQAGqeWLwRjP7KDtd\nSF9cD0BpDbUEHpc0Q9IsSZ2SHurvjma20Mw2mNmGSqUyxIcDMFyGVALuvtfdD7v7EUnLJV2QuO8y\nd29199a8Z9cB1N+QSsDMmnt9O1/Slv7uC6DczN3TdzB7XtLFkiZJ2ivpnuz7WZJc0g5Ji9y9M+/B\nmpqaPO8982V26qmnJvM9e/Yk85kzZybzTz/9NJlzOpU2duzYZD579uxk3tbWlszzPpch7+9SkTo6\nOtTd3W19ZbnH5+5+XR+bn6p6KgClwLJhIDhKAAiOEgCCowSA4CgBIDhKAAiOJXyDkPd+8sWLFyfz\nTZs2JfOtW7cOeqZjyXHHpX8n5a2T+Oabb5L5Y489lsxPOeWUZB72egIAjm2UABAcJQAERwkAwVEC\nQHCUABAcJQAExzqBQVi7dm0yHz16dDJ/8sknk/m555476JlGkvHjxyfzvHUSkyZNSuZ5+/+cc85J\n5lFxJAAERwkAwVECQHCUABAcJQAERwkAwVECQHCsExiE888/P5kvX748mS9ZsiSZz5s3b9AzlYlZ\nn5e1/5tp06Yl81dffTWZ5+2f7777LpmjbxwJAMFRAkBwlAAQHCUABEcJAMFRAkBwlAAQHOsEBmH/\n/v3J/N13303mDz74YDK/6qqrkvl7772XzA8ePJjMm5ubk/lJJ52UzE8//fRkvnLlymR+yy23JPP1\n69cn866urmSOock9EjCzaWb2jpltM7OtZnZztn2imb1tZh3Z1wnDPy6AWhvI6UBF0q3u/mtJ/yzp\nj2b2a0l3Slrt7i2SVmffAxhhckvA3TvdfWN2+3tJ7ZKmSrpS0tHjv5WSRvaaVyCoQT0xaGbTJc2W\ntF7SZHfvzKKvJE2u6WQA6mLAJWBmYyS9JGmxu//dMzTu7pK8n59baGYbzGxD3gdKAqi/AZWAmTWq\npwCedfeXs817zaw5y5sl7evrZ919mbu3untrQwMvRgBlM5BXB0zSU5La3f3hXtHrkhZktxdIeq32\n4wEYbgP51fwbSb+X9LGZbc62LZH0gKQXzOwPknZKumZ4RiyP1tbWZN7W1pbM8z5XYM6cOcl806ZN\nyTxvncCMGTOS+aWXXprM89YZPPPMM8l86dKlyXzjxo3JHMMjtwTc/V1J/V0t4re1HQdAvbFsGAiO\nEgCCowSA4CgBIDhKAAiOEgCCYwnfIKxduzaZP/roo8m8vb09mV900UXJfOrUqcl8xYoVyfzss89O\n5tu3b0/mX375ZTLv7u5O5qwDKCeOBIDgKAEgOEoACI4SAIKjBIDgKAEgOEoACI51AoNw6NChZH73\n3Xcn8wMHDiTzs846K5mffPLJyfy8885L5jt37kzm69atq+rnMTJxJAAERwkAwVECQHCUABAcJQAE\nRwkAwVECQHDW8wli9dHU1OQtLS11ezwAPTo6OtTd3d3nRwdwJAAERwkAwVECQHCUABAcJQAERwkA\nwVECQHC5JWBm08zsHTPbZmZbzezmbPu9ZrbbzDZnf9Ifbg+glAZyUZGKpFvdfaOZjZX0gZm9nWWP\nuPufhm88AMMttwTcvVNSZ3b7ezNrl5T+KBwAI8agnhMws+mSZktan2260cw+MrOnzWxCjWcDUAcD\nLgEzGyPpJUmL3b1L0uOSZkiapZ4jhYf6+bmFZrbBzDZUKpUajAyglgZUAmbWqJ4CeNbdX5Ykd9/r\n7ofd/Yik5ZIu6Otn3X2Zu7e6e2tDA9c1BcpmIK8OmKSnJLW7+8O9tjf3utt8SVtqPx6A4TaQX82/\nkfR7SR+b2eZs2xJJ15nZLEkuaYekRcMyIYBhNZBXB96V1Nf7kFfVfhwA9caKQSA4SgAIjhIAgqME\ngOAoASA4SgAIjhIAgqMEgOAoASA4SgAIjhIAgqMEgOAoASA4SgAIjhIAgjN3r9+DmX0taWevTZMk\n7a/bAIPHfNUp83xlnk2q/Xynuvsv+wrqWgL/8OBmG9y9tbABcjBfdco8X5lnk+o7H6cDQHCUABBc\n0SWwrODHz8N81SnzfGWeTarjfIU+JwCgeEUfCQAoGCUABEcJAMFRAkBwlAAQ3P8BzmKKN8qMZ0kA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.gray()\n",
    "plt.matshow(pesos[1] * x_train[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-DHm5zBCdDsX"
   },
   "source": [
    "# Introdução a redes neurais profundas e backpropagation\n",
    "\n",
    "\n",
    "- ## Consideremos um pequeno problema de um semáforo\n",
    "\n",
    "![alt text](https://drive.google.com/uc?export=view&id=1s8DFSxoYGMKot8yFhWPgBVyyasY1PCai)\n",
    "\n",
    "\n",
    "## Conseguimos compor uma relação apenas olhando o conjunto de dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "beoMBKBXff-g"
   },
   "source": [
    "#1º Passo - Compor os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPHHFktfdY24"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "luzes = np.array([[1,0,1],[0,1,1],[0,0,1],[1,1,1],[0,1,1],[1,0,1]])\n",
    "respostas = np.array([0,1,0,1,1,0]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lp3415ijgqiz"
   },
   "source": [
    "#2º Passo - Montar a rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zSkNTkUSPgrd",
    "outputId": "e63f618a-bb04-40b8-e9f0-6e85b7771fc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.001010695656373406, 1.02150570981207e-06)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def rede_neural(entrada,saida):\n",
    "  wt = np.random.random((3,))\n",
    "  alpha = 0.1\n",
    "  for i in range(30):\n",
    "\n",
    "    pred = entrada.dot(wt)\n",
    "    erro = (pred-saida)**2\n",
    "    delta = pred-saida\n",
    "    delta_wt = delta*entrada\n",
    "    wt -= alpha * delta_wt\n",
    "    \n",
    "  return pred,erro\n",
    "\n",
    "\n",
    "entradas = luzes[0]\n",
    "saida = respostas[0]\n",
    "print(rede_neural(entradas,saida))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DZW1RkIZhTOb"
   },
   "source": [
    "#3º Passo - Aprendendo o conjunto de dados inteiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Nu82dMOQg3XE",
    "outputId": "d5e0274a-b585-4c5e-dd5c-f2eb4ce50571"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previsao 0.7795569191304039\n",
      "Previsao 0.5176269402664414\n",
      "Previsao 0.3139698482879829\n",
      "Previsao 0.9406175603740509\n",
      "Previsao 0.5945810553095446\n",
      "Previsao 0.692904238843116\n",
      "Erro total 1.5869769036113914\n",
      "Previsao 0.5543233910744928\n",
      "Previsao 0.5509420812558748\n",
      "Previsao 0.24923603077347672\n",
      "Previsao 0.8549585358878822\n",
      "Previsao 0.6448383547497758\n",
      "Previsao 0.5279653590041051\n",
      "Erro total 0.9969702761918142\n",
      "Previsao 0.42237228720328407\n",
      "Previsao 0.6208369191790817\n",
      "Previsao 0.21721528209371616\n",
      "Previsao 0.8335468628848967\n",
      "Previsao 0.7082386345569145\n",
      "Previsao 0.4165593736026767\n",
      "Erro total 0.6556985225869238\n",
      "Previsao 0.33324749888214134\n",
      "Previsao 0.6916102203970498\n",
      "Previsao 0.19717349485197666\n",
      "Previsao 0.8338343090464736\n",
      "Previsao 0.7668039650231475\n",
      "Previsao 0.334272369269201\n",
      "Erro total 0.4387649831827348\n",
      "Previsao 0.26741789541536076\n",
      "Previsao 0.7532741455500618\n",
      "Previsao 0.18189587693635453\n",
      "Previsao 0.8411407535873419\n",
      "Previsao 0.8162015780289456\n",
      "Previsao 0.27056900556328406\n",
      "Erro total 0.2976977949502302\n",
      "Previsao 0.21645520445062727\n",
      "Previsao 0.8042588414217653\n",
      "Previsao 0.16884375093752269\n",
      "Previsao 0.8504172265244625\n",
      "Previsao 0.8564392527387674\n",
      "Previsao 0.2201265337458038\n",
      "Erro total 0.20511605405974462\n",
      "Previsao 0.17610122699664302\n",
      "Previsao 0.8455286261167693\n",
      "Previsao 0.15709808923152582\n",
      "Previsao 0.8599431217243745\n",
      "Previsao 0.8887244676253878\n",
      "Previsao 0.17975723895507126\n",
      "Erro total 0.14386369535360982\n",
      "Previsao 0.143805791164057\n",
      "Previsao 0.8786232710883974\n",
      "Previsao 0.14630289125264448\n",
      "Previsao 0.869147742315215\n",
      "Previsao 0.9144387792824106\n",
      "Previsao 0.14727859030585735\n",
      "Erro total 0.10295097087685416\n",
      "Previsao 0.11782287224468588\n",
      "Previsao 0.9050408771708741\n",
      "Previsao 0.13629971599547572\n",
      "Previsao 0.8778572242203372\n",
      "Previsao 0.9348312852930842\n",
      "Previsao 0.12106966510573786\n",
      "Erro total 0.0753007596734398\n",
      "Previsao 0.09685573208459028\n",
      "Previsao 0.9260724885154346\n",
      "Previsao 0.12700110487400976\n",
      "Previsao 0.8860341122670656\n",
      "Previsao 0.9509510578715334\n",
      "Previsao 0.09987529808816131\n",
      "Erro total 0.05634468789003825\n",
      "Previsao 0.07990023847052904\n",
      "Previsao 0.9427832926413577\n",
      "Previsao 0.11834659445274405\n",
      "Previsao 0.8936872417273551\n",
      "Previsao 0.9636545263223408\n",
      "Previsao 0.08270430108930796\n",
      "Erro total 0.04312711357423632\n",
      "Previsao 0.06616344087144636\n",
      "Previsao 0.9560368468617972\n",
      "Previsao 0.11028729932024489\n",
      "Previsao 0.9008405162481458\n",
      "Previsao 0.9736326443077841\n",
      "Previsao 0.06876697039854532\n",
      "Erro total 0.03373038501508422\n",
      "Previsao 0.05501357631883626\n",
      "Previsao 0.9665280607744892\n",
      "Previsao 0.10278039258344035\n",
      "Previsao 0.9075220717554271\n",
      "Previsao 0.9814399950101619\n",
      "Previsao 0.05743160186717445\n",
      "Erro total 0.02690570328517166\n",
      "Previsao 0.04594528149373956\n",
      "Previsao 0.9748143076720381\n",
      "Previsao 0.0957870275452422\n",
      "Previsao 0.9137605102656519\n",
      "Previsao 0.9875206413299759\n",
      "Previsao 0.04819192548713566\n",
      "Erro total 0.021835888300144195\n",
      "Previsao 0.038553540389708534\n",
      "Previsao 0.9813419664762962\n",
      "Previsao 0.08927146639584117\n",
      "Previsao 0.9195835958097489\n",
      "Previsao 0.9922297073795032\n",
      "Previsao 0.040641799124652975\n",
      "Erro total 0.01798282375040296\n",
      "Previsao 0.03251343929972238\n",
      "Previsao 0.986468242061165\n",
      "Previsao 0.0832006413887778\n",
      "Previsao 0.9250178153549379\n",
      "Previsao 0.9958509664390667\n",
      "Previsao 0.03445520337988938\n",
      "Erro total 0.014989282469101443\n",
      "Previsao 0.02756416270391151\n",
      "Previsao 0.9904788365428733\n",
      "Previsao 0.07754387880783215\n",
      "Previsao 0.930088249054525\n",
      "Previsao 0.9986110315426103\n",
      "Previsao 0.029370305662892622\n",
      "Erro total 0.012615685768078278\n",
      "Previsao 0.023496244530314098\n",
      "Previsao 0.9936021702147676\n",
      "Previsao 0.07227269082653796\n",
      "Previsao 0.9348185548653969\n",
      "Previsao 1.000690756116081\n",
      "Previsao 0.025176722935433236\n",
      "Erro total 0.010699312883912215\n",
      "Previsao 0.02014137834834659\n",
      "Previsao 0.9960207947644869\n",
      "Previsao 0.0673606010409097\n",
      "Previsao 0.9392309978688173\n",
      "Previsao 1.002234376133735\n",
      "Previsao 0.02170532591100067\n",
      "Erro total 0.00912794499829964\n",
      "Previsao 0.01736426072880054\n",
      "Previsao 0.9978805422430078\n",
      "Previsao 0.06278299064828262\n",
      "Previsao 0.943346498440035\n",
      "Previsao 1.003356835041571\n",
      "Previsao 0.0188200721017473\n",
      "Erro total 0.007822796261000018\n",
      "Previsao 0.015056057681397839\n",
      "Previsao 0.9992978550549422\n",
      "Previsao 0.058516959751485034\n",
      "Previsao 0.9471846889569443\n",
      "Previsao 1.0041496502774163\n",
      "Previsao 0.01641146184534506\n",
      "Erro total 0.006727425216887168\n",
      "Previsao 0.013129169476276042\n",
      "Previsao 1.000365657089771\n",
      "Previsao 0.05454120101176125\n",
      "Previsao 0.9507639744309231\n",
      "Previsao 1.004685610684456\n",
      "Previsao 0.014391293816237397\n",
      "Erro total 0.005800501903079781\n",
      "Previsao 0.011513035052989923\n",
      "Previsao 1.001158055660642\n",
      "Previsao 0.05083588394606029\n",
      "Previsao 0.9541015946641751\n",
      "Previsao 1.0050225372010726\n",
      "Previsao 0.012688461428779427\n",
      "Erro total 0.005011064711359291\n",
      "Previsao 0.010150769143023541\n",
      "Previsao 1.0017341067036778\n",
      "Previsao 0.047382548637381415\n",
      "Previsao 0.9572136865058738\n",
      "Previsao 1.0052062931980295\n",
      "Previsao 0.011245583159335215\n",
      "Erro total 0.004335388407503533\n",
      "Previsao 0.008996466527468175\n",
      "Previsao 1.0021408295897432\n",
      "Previsao 0.0441640078755983\n",
      "Previsao 0.9601153452716367\n",
      "Previsao 1.0052731938299075\n",
      "Previsao 0.01001630103812231\n",
      "Erro total 0.003754897695402904\n",
      "Previsao 0.008013040830497843\n",
      "Previsao 1.002415620877064\n",
      "Previsao 0.04116425690331563\n",
      "Previsao 0.9628206846846957\n",
      "Previsao 1.0052519340743804\n",
      "Previsao 0.008963114541983112\n",
      "Erro total 0.003254761815104268\n",
      "Previsao 0.00717049163358649\n",
      "Previsao 1.0025881866419473\n",
      "Previsao 0.03836839005532476\n",
      "Previsao 0.9653428948953752\n",
      "Previsao 1.0051651313289505\n",
      "Previsao 0.0080556435251719\n",
      "Erro total 0.002822934924281394\n",
      "Previsao 0.006444514820137519\n",
      "Previsao 1.0026820892286294\n",
      "Previsao 0.03576252366996583\n",
      "Previsao 0.9676942982791882\n",
      "Previsao 1.0050305593600692\n",
      "Previsao 0.007269234974405927\n",
      "Erro total 0.002449490141404539\n",
      "Previsao 0.005815387979524741\n",
      "Previsao 1.0027159851926624\n",
      "Previsao 0.0333337247243842\n",
      "Previsao 0.9698864028216607\n",
      "Previsao 1.0048621351173592\n",
      "Previsao 0.006583845315847065\n",
      "Erro total 0.002126148628981927\n",
      "Previsao 0.005267076252677652\n",
      "Previsao 1.002704615937035\n",
      "Previsao 0.03106994470748782\n",
      "Previsao 0.9719299529798299\n",
      "Previsao 1.0046707076829131\n",
      "Previsao 0.005983143573432558\n",
      "Erro total 0.0018459395607388278\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def rede_neural(entradas,saidas):\n",
    "  wt = np.random.random((3,))\n",
    "  alpha = 0.1\n",
    "  for _ in range(30):\n",
    "    erro_total = 0\n",
    "    for i in range(len(entradas)):\n",
    "      entrada = entradas[i]\n",
    "      saida = saidas[i]\n",
    "      pred = entrada.dot(wt)\n",
    "      erro = (pred-saida)**2\n",
    "      erro_total+=erro\n",
    "      delta = pred-saida\n",
    "      delta_wt = delta*entrada\n",
    "      wt -= alpha * delta_wt\n",
    "      print('Previsao',pred)\n",
    "    print('Erro total',erro_total)\n",
    "\n",
    "    \n",
    "  return pred,wt\n",
    "\n",
    "\n",
    "\n",
    "pred,wts = rede_neural(luzes,respostas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tIanZrLyjWVG"
   },
   "source": [
    "# Gradiente descendente completo, em lotes e estocástico\n",
    "\n",
    "\n",
    "- ## O gradiente descendente estocástico aprende um exemplo do dataset por vez, como acabamos de utilizar no exemplo anterior, utilizando a técnica do delta do gradiente descendente para diminuir o erro de uma forma que os pesos funcionem para todos os exemplos.\n",
    "\n",
    "- ## O gradiente completo calcula uma média de variação de pesos sobre todo o dataset,atualizando os pesos apenas quando calcula uma média total.\n",
    "\n",
    "- ## O gradiente em lotes atualiza os pesos após um número *n* de dados, sendo eles chamados de *batch size*, veremos sobre ele futuramente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WF_bw16TlCu8"
   },
   "source": [
    "# Redes neurais aprendem correlações\n",
    "\n",
    "Observemos os pesos da rede neural treinada abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sCZOZSEGiD-M",
    "outputId": "573578c8-94d1-4204-98ce-59efbfd2d7b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02295868,  0.97470612,  0.0278343 ])"
      ]
     },
     "execution_count": 281,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jTTBC_pDmFdJ"
   },
   "source": [
    "# Pressão para cima e para baixo\n",
    "\n",
    "- Analisando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "As_tFMcrlQ-8",
    "outputId": "9367ac3b-9383-4075-fb31-80307d6226c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1]])"
      ]
     },
     "execution_count": 283,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qGddLqzWnuEY",
    "outputId": "6af5a8da-5f9e-40df-b098-8fa445570456"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 288,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respostas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZzaNj2Mn9tR"
   },
   "source": [
    "# A previsão é uma soma ponderada das entradas. O algoritmo de aprendizado recompensa as entradas que tem correlação com a saída com uma pressão para cima (aproximando de 1) e pune as discorrelatas diminuindo os pesos para perto de 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "75vlSkpnqxOA"
   },
   "source": [
    "# Casos de borda \n",
    "\n",
    "- ## Overfitting\n",
    "\n",
    "Olhando para o primeiro caso de aprendizado, o que aconteceria se os pesos das variáveis dos cantos fossem 0.5 e -0.5?\n",
    "\n",
    "O error é dividido entre todos os pesos. Se uma configuração de pesos acidentalmente cria a correlação perfeita entre o conjunto de saída sem dar o peso maior para as melhores entradas, a rede neural vai parar de aprender.\n",
    "\n",
    "\n",
    "- ## Conflito de pressões\n",
    "\n",
    "Considerem a parte direita da tabela de pressões (desenhada no quadro)\n",
    "\n",
    "O peso da direita tem pressão igual para cima e para baixo, o que devemos fazer com este peso então?\n",
    "\n",
    "Consideremos o caso extremo, em que os pesos da esquerda e do meio estão ajustados perfeitamente para 0 e 1 respectivamente, o que acontece com a rede? Se o peso da direita está acima de 0, a rede prevê muito alto, e se o peso está abaixo de 0, prevê muito baixo.\n",
    "\n",
    "Enquanto os nós aprendem, eles absorvem uma parte do erro e da correlação. Eles causam a rede neural prever com um poder correlativo moderado, que reduz o erro.\n",
    "\n",
    "\n",
    "- Mas nem sempre a vida são flores\n",
    "\n",
    "Acontecemos por acaso de pegar um conjunto de dados em que a coluna do meio tem correlação direta com a saída, o que fez com que a coluna do meio não tivesse tanta influência no resultado.\n",
    "\n",
    "Uma maneira que veremos futuramente para corrigir este problema será a regularização, que forçará pesos conflitantes para zero.\n",
    "\n",
    "\n",
    "- ## Se a rede neural procura por correlação entre a coluna de entrada dos dados e a coluna de saída, o que a rede neural faria com o seguinte conjunto de dados?\n",
    "\n",
    "![alt text](https://drive.google.com/uc?export=view&id=1nve2wpgaYb3xGh7U8hkYYxo3uNuweN_F)\n",
    "\n",
    "Não há correlação entre qualquer coluna de entrada e coluna de saída. Qualquer peso tem uma quantia igual de pressão para cima e para baixo. Este é um problema de verdade para redes neurais.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vppZOyzk7Wad"
   },
   "source": [
    "# Aprendendo correlação indireta\n",
    "\n",
    "Redes neurais procuram por correlação entre as suas camadas de entrada e saída. Você atribui os valores para a camada de entrada como as linhas de entrada dos seus dados e tenta treinar a rede de modo que a camada de saída seja igual ao dataset de saída. \n",
    "\n",
    "\n",
    "## Criando a correlação \n",
    "\n",
    "Abaixo está a foto de uma rede neural. Basicamente, empilhamos uma rede neural em cima da outra. A camada do meio (layer_1) representa o conjunto de dados intermediário. O objetivo é treinar a rede neural mesmo que não tenhamos correlação direta entre a camada de entrada (layer_0) e a camada de saída (layer_2)\n",
    "\n",
    "![alt text](https://drive.google.com/uc?export=view&id=1Mio1iT25iWZOyYwIfpO6wDP8hVfoHptc)\n",
    "\n",
    "\n",
    "Se olharmos para a parte superior da rede neural, (layer_1 para layer_2), não teremos novidade no código para a nossa rede neural. A parte que precisamos pensar é, como atualizaremos os pesos entre a camada 1 e camada 0? O que eles usam como medida de erro? No caso, precisamos saber como os valores de delta na camada 1 podem ajudar a camada 2 a fazer previsões certas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AJ_XUsk3E30w"
   },
   "source": [
    "# Backpropagation ao resgate\n",
    "\n",
    "Qual é a previsão da camada 1 para a camada 2? É a média ponderada de todos os valores na camada 1. Se a camada 2 passou por X, como saber quais valores da camada 1 contribuiram para o erro? Os com maiores pesos contribuiram mais.\n",
    "\n",
    "Consideremos o caso extremo, digamos que um dos pesos da camada 1 para a camada 2 é igual a zero. Qual seria a contribuição do pesos da camada 1 para o erro? Zero.\n",
    "\n",
    "É tão simples que até parece engenharia elétrica, os pesos da camada 1 para a camada 2 descrevem exatamente o quanto cada nó da camada 1 contribuiu para a previsão da camada 2. Isto significa que os pesos descrevem exatamente o quanto os nós da camada 1 contribuiram para o erro. \n",
    "\n",
    "Como usar o delta da camada 2 para descobrir o delta da camada 1 então? Multiplicamos o delta por cada peso da camada 1, é quase como a lógica de previsão reversa.\n",
    "\n",
    "O processo de mover o sinal do delta por aí é chamado de backpropagation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3kW9u3XLVknY"
   },
   "source": [
    "# E por que funciona?\n",
    "\n",
    "Aprendemos que o delta diz a direção e a quantidade que devemos mudar o valor de um nó para que isso funcione. Tudo que o backpropagation faz é dizer, se você quer que este nó tenha um valor X maior que antes, você deve multiplicar os nós anteriores por $ x * pesos_1_2 $ para cima ou para baixo, porque esses pesos estavam aumentando a previsão por pesos_1_2 vezes.\n",
    "\n",
    "Quando usamos na direção contrária, os pesos amplificam o erro pela quantia aproproiada. Assim sabemos o quanto cada camada deve subir ou descer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIv09AJgWP9A"
   },
   "source": [
    "# MAS A VIDA... AAAAH A VIDA, ELA É UMA CAIXINHA DE SURPRESAS\n",
    "\n",
    "## Linear vs não linear\n",
    "\n",
    "Podemos treinar a rede neural do jeito que ela está disposta agora, mas ela não iria convergir, por quê?\n",
    "\n",
    "Bem, se trata de álgebra simples, se há duas multiplicações, podemos representar elas com apenas uma multiplicação. Vejamos o exemplo\n",
    "\n",
    "$$ 5 * 10 * 2 = 100 $$\n",
    "\n",
    "$$ 5 * 20 = 100 $$\n",
    "\n",
    "Como todos sabemos, redes neurais aplicam multiplicações de matrizes, logo se temos uma rede com 3 camadas agora, há uma mesma rede neural com apenas 2 camadas que resolveria o mesmo problema para nós, então voltamos ao ponto inicial.\n",
    "\n",
    "\n",
    "Como sabemos, o nosso dataset de semáforos não possui uma correlação linear, logo nossa rede neural não seria capaz de convergir para ela com apenas uma relação linear. O que precisamos fazer então? \n",
    "\n",
    "Precisamos que a camada intermediária se relacione às vezes com a entrada e às vezes não. Isto dá a camada do meio não apenas ser x% correlacionada com uma entrada e y% correlacionada com outra entrada. Ao invés disso, ela pode ser x% correlacionada com uma entrada apenas quando quiser ser, mas outras vezes não se correlacionar.\n",
    "\n",
    "Isto é chamado de correlação condicional.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xj1bDtiodbZ0"
   },
   "source": [
    "# Qual o segredo para a correlação condicional?\n",
    "\n",
    "## Simplesmente desligar o nó quando o peso seria negativo\n",
    "\n",
    "Parece ser simples demais para funcionar, mas pensemos: Se o valor de um nó fosse para menos que 0, o nó normalmente teria a mesma correlação com a entrada como sempre. Só seria negativa. Mas se desligarmos o nó, quando ele fosse negativo, ele será desligado e não terá correlação com a entrada.\n",
    "\n",
    "O termo técnico para desligar o nó para quando ele fosse negativo é não linearidade. Sem essa técnica, a rede neural seria linear, logo a camada de saída faria a mesma correlação que em uma rede com apenas 2 camadas.\n",
    "Há vários tipos de não linearidades, a apresentada aqui, que em muitos casos é a melhor a ser utilizada e por acaso é a mais simples, é chamada _relu_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWXn2ZcHfEtg"
   },
   "source": [
    "# Nossa primeira rede neural profunda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xzoIovuIfDvB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def relu(x):\n",
    "    return (x > 0) * x \n",
    "\n",
    "alpha = 0.2\n",
    "hidden_size = 4\n",
    "\n",
    "streetlights = np.array( [[ 1, 0, 1 ],\n",
    "                          [ 0, 1, 1 ],\n",
    "                          [ 0, 0, 1 ],\n",
    "                          [ 1, 1, 1 ] ] )\n",
    "\n",
    "walk_vs_stop = np.array([[ 1, 1, 0, 0]]).T\n",
    "\n",
    "weights_0_1 = 2*np.random.random((3,hidden_size)) - 1\n",
    "weights_1_2 = 2*np.random.random((hidden_size,1)) - 1\n",
    "\n",
    "layer_0 = streetlights[0]\n",
    "layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "layer_2 = np.dot(layer_1,weights_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SNuQste6fUvF"
   },
   "source": [
    "# E como funciona o backpropagation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "id": "lGZASHWBqwoe",
    "outputId": "e0db7b73-9d0a-4e6f-f58c-a41ced61f3a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.6342311598444467\n",
      "Error:0.35838407676317513\n",
      "Error:0.0830183113303298\n",
      "Error:0.006467054957103705\n",
      "Error:0.0003292669000750734\n",
      "Error:1.5055622665134859e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def relu(x):\n",
    "    return (x > 0) * x # returns x if x > 0\n",
    "                       # return 0 otherwise\n",
    "\n",
    "def relu2deriv(output):\n",
    "    return output>0 # returns 1 for input > 0\n",
    "                    # return 0 otherwise\n",
    "alpha = 0.2\n",
    "hidden_size = 4\n",
    "\n",
    "weights_0_1 = 2*np.random.random((3,hidden_size)) - 1\n",
    "weights_1_2 = 2*np.random.random((hidden_size,1)) - 1\n",
    "\n",
    "for iteration in range(60):\n",
    "   layer_2_error = 0\n",
    "   for i in range(len(streetlights)):\n",
    "      layer_0 = streetlights[i:i+1]\n",
    "      layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "      layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "      layer_2_error += np.sum((layer_2 - walk_vs_stop[i]) ** 2)\n",
    "\n",
    "      layer_2_delta = (walk_vs_stop[i] - layer_2)\n",
    "      layer_1_delta=layer_2_delta.dot(weights_1_2.T)*relu2deriv(layer_1)\n",
    "\n",
    "      weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "      weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "\n",
    "   if(iteration % 10 == 9):\n",
    "      print(\"Error:\" + str(layer_2_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kZwOAw4vf8F-"
   },
   "source": [
    "# Colocando tudo junto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "id": "YepkPQNln9Pj",
    "outputId": "f1ec4ab8-6824-4468-dcac-b60feea6285d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro:0.6342311598444467\n",
      "Erro:0.35838407676317513\n",
      "Erro:0.0830183113303298\n",
      "Erro:0.006467054957103705\n",
      "Erro:0.0003292669000750734\n",
      "Erro:1.5055622665134859e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def relu(x):\n",
    "    return (x > 0) * x \n",
    "                      \n",
    "\n",
    "def relu2deriv(output):\n",
    "    return output>0 \n",
    "                    \n",
    "def rede_neural(entrada,saida):\n",
    "  alpha = 0.2\n",
    "  hidden_size = 4\n",
    "  weights_0_1 = 2*np.random.random((3,hidden_size)) - 1\n",
    "  weights_1_2 = 2*np.random.random((hidden_size,1)) - 1\n",
    "\n",
    "  for iteration in range(60):\n",
    "    layer_2_error = 0\n",
    "    for i in range(len(entrada)):\n",
    "        layer_0 = entrada[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "        layer_2_error += np.sum((layer_2 - saida[i]) ** 2)\n",
    "\n",
    "        layer_2_delta = (layer_2 - saida[i])\n",
    "        layer_1_delta=layer_2_delta.dot(weights_1_2.T)*relu2deriv(layer_1)\n",
    "\n",
    "        weights_1_2 -= alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 -= alpha * layer_0.T.dot(layer_1_delta)\n",
    "\n",
    "    if(iteration % 10 == 9):\n",
    "        print(\"Erro:\" + str(layer_2_error))\n",
    "\n",
    "streetlights = np.array( [[ 1, 0, 1 ],\n",
    "                          [ 0, 1, 1 ],\n",
    "                          [ 0, 0, 1 ],\n",
    "                          [ 1, 1, 1 ] ] )\n",
    "\n",
    "walk_vs_stop = np.array([[ 1, 1, 0, 0]]).T\n",
    "    \n",
    "\n",
    "rede_neural(streetlights,walk_vs_stop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6CxA3OrHg5aH"
   },
   "source": [
    "# Aplicando a rede neural no dataset do mnist de digitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qoy5YGDyn0IQ"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels),10))\n",
    "for i,l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i,l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XWQpQHT7g8e8"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels),10))\n",
    "for i,l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i,l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1\n",
    "    \n",
    "np.random.seed(1)\n",
    "relu = lambda x:(x>=0) * x \n",
    "relu2deriv = lambda x: x>=0 \n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 350, 40, 784, 10)\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        layer_0 = images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "        error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == \\\n",
    "                                        np.argmax(labels[i:i+1]))\n",
    "\n",
    "        layer_2_delta = (labels[i:i+1] - layer_2)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)\\\n",
    "                                    * relu2deriv(layer_1)\n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Lz0QNAHzhXk4",
    "outputId": "f2719f7a-b617-4f26-e9e0-e90108158867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro = 0.10881979854066472 Porcentagem de acerto = 100.0\n"
     ]
    }
   ],
   "source": [
    "print('Erro =', error/len(images), \"Porcentagem de acerto =\",100*correct_cnt/float(len(images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqE6fOkgpMHL"
   },
   "source": [
    "# Criamos a rede neural perfeita!!! \n",
    "\n",
    "## 100% de taxa de acerto na nosa primeira tentativa, poderíamos querer algo de melhor? Basta apenas aplicar ele no resto do dataset e ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yAdNtWsQl4q0"
   },
   "outputs": [],
   "source": [
    "if(j % 10 == 0 or j == iterations-1):\n",
    " error, correct_cnt = (0.0, 0)\n",
    " for i in range(len(test_images)):\n",
    "  layer_0 = test_images[i:i+1]\n",
    "  layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "  layer_2 = np.dot(layer_1,weights_1_2)\n",
    "  error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
    "  correct_cnt += int(np.argmax(layer_2) == \\\n",
    "  np.argmax(test_labels[i:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FwdnxO43m2G1",
    "outputId": "ac6573ba-3f4a-443e-e286-6064e3ed83f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro = 0.6534055358949858 Porcentagem de acerto = 70.73\n"
     ]
    }
   ],
   "source": [
    "print('Erro =', error/len(test_images), \"Porcentagem de acerto =\",100*correct_cnt/float(len(test_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xuqWRE7XpgTM"
   },
   "source": [
    "# Mas como assim?\n",
    "\n",
    "# Nossa rede neural memorizou as respostas, não aprendeu nada\n",
    "\n",
    "Isto foi causado pelo overfitting, nossa rede neural viu tanto os dados que se adaptou bem a eles, muito bem digamos de passagem e acabou por perder sua maior força, que é a abstração\n",
    "\n",
    "- ## Como resolver isto?\n",
    "\n",
    "## Regularização ao resgate!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VKK-aOMgrUH4"
   },
   "source": [
    "# 1ª estratégia de regularização - early stopping\n",
    "\n",
    "Se formos analisar o aumento da acurácia da rede neural, vemos que ela cresce rapidamente no início e após algumas iterações ela começa a estabilizar, podendo chegar ao extremo de chegar ao 100%, então o que aconteceria se pararmos antes?\n",
    "\n",
    "E como descobrimos quando parar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dw4WYsNvsKfu"
   },
   "source": [
    "# 2ª estratégia - a favorita de todos - dropout\n",
    "\n",
    "E se desligarmos aleatoriamente alguns neurônios durante o treinamento?\n",
    "\n",
    "Qual o pensamento por trás disso? Com o dropout, fazemos uma rede neural grande funcionar como uma rede neural pequena, treinando apenas subseções da rede por vez, de forma que as subseções não farão o overfit.\n",
    "\n",
    "Como o dropout funciona em código?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1uXKstmfobKL"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "layer_0 = images[i:i+1]\n",
    "dropout_mask = np.random.randint(2,size=layer_1.shape)\n",
    "\n",
    "layer_1 *= dropout_mask * 2\n",
    "layer_2 = np.dot(layer_1, weights_1_2)\n",
    "\n",
    "error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
    "\n",
    "correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i+i+1]))\n",
    "\n",
    "layer_2_delta = (labels[i:i+1] - layer_2)\n",
    "layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "\n",
    "layer_1_delta *= dropout_mask\n",
    "\n",
    "weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2O37g_sntJhb"
   },
   "source": [
    "# Rede neural completa com dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "S0RyEX4btGaz",
    "outputId": "71b45790-0550-4e61-fd96-ef11e8e846a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It =  0 Erro = 0.8911648358661146 Porcentagem de acerto = 41.3\n",
      "Erro de teste 0.6413979051989774 Porcentagem de acerto do teste= 63.33\n",
      "It =  10 Erro = 0.4720771230935533 Porcentagem de acerto = 76.4\n",
      "Erro de teste 0.4585389172141942 Porcentagem de acerto do teste= 78.7\n",
      "It =  20 Erro = 0.43086224639373016 Porcentagem de acerto = 80.9\n",
      "Erro de teste 0.41555953273733903 Porcentagem de acerto do teste= 81.33\n",
      "It =  30 Erro = 0.4156517386208305 Porcentagem de acerto = 81.1\n",
      "Erro de teste 0.42130185454540425 Porcentagem de acerto do teste= 81.14\n",
      "It =  40 Erro = 0.4132277446553964 Porcentagem de acerto = 82.7\n",
      "Erro de teste 0.41997162343638855 Porcentagem de acerto do teste= 81.12\n",
      "It =  50 Erro = 0.3922295064535343 Porcentagem de acerto = 83.6\n",
      "Erro de teste 0.40988065318373573 Porcentagem de acerto do teste= 81.33\n",
      "It =  60 Erro = 0.4024713104762388 Porcentagem de acerto = 83.6\n",
      "Erro de teste 0.4126732067474676 Porcentagem de acerto do teste= 82.36\n",
      "It =  70 Erro = 0.38331533975482224 Porcentagem de acerto = 85.7\n",
      "Erro de teste 0.4120814761281567 Porcentagem de acerto do teste= 80.33\n",
      "It =  80 Erro = 0.3867211801939443 Porcentagem de acerto = 85.4\n",
      "Erro de teste 0.4106666055222616 Porcentagem de acerto do teste= 80.54\n",
      "It =  90 Erro = 0.3768982481488134 Porcentagem de acerto = 86.8\n",
      "Erro de teste 0.4110712970390881 Porcentagem de acerto do teste= 81.44\n",
      "It =  100 Erro = 0.369729453678139 Porcentagem de acerto = 86.4\n",
      "Erro de teste 0.4112206488646485 Porcentagem de acerto do teste= 79.03\n",
      "It =  110 Erro = 0.371652563514406 Porcentagem de acerto = 86.8\n",
      "Erro de teste 0.41100675563184225 Porcentagem de acerto do teste= 80.03\n",
      "It =  120 Erro = 0.35306288741129355 Porcentagem de acerto = 85.7\n",
      "Erro de teste 0.40281439789253654 Porcentagem de acerto do teste= 80.46\n",
      "It =  130 Erro = 0.35240806479500736 Porcentagem de acerto = 86.7\n",
      "Erro de teste 0.4087897420155367 Porcentagem de acerto do teste= 80.91\n",
      "It =  140 Erro = 0.35558111029652917 Porcentagem de acerto = 88.5\n",
      "Erro de teste 0.4058078286115294 Porcentagem de acerto do teste= 80.83\n",
      "It =  150 Erro = 0.3424931459295569 Porcentagem de acerto = 88.3\n",
      "Erro de teste 0.40407526847433295 Porcentagem de acerto do teste= 81.07\n",
      "It =  160 Erro = 0.36103166208369897 Porcentagem de acerto = 87.6\n",
      "Erro de teste 0.3996582711860419 Porcentagem de acerto do teste= 81.46\n",
      "It =  170 Erro = 0.34491348449746606 Porcentagem de acerto = 88.9\n",
      "Erro de teste 0.40428123966229046 Porcentagem de acerto do teste= 80.74\n",
      "It =  180 Erro = 0.33312957759339173 Porcentagem de acerto = 89.2\n",
      "Erro de teste 0.3993862505882355 Porcentagem de acerto do teste= 80.7\n",
      "It =  190 Erro = 0.3353380487528952 Porcentagem de acerto = 89.8\n",
      "Erro de teste 0.40748792613280743 Porcentagem de acerto do teste= 80.66\n",
      "It =  200 Erro = 0.3477299441526187 Porcentagem de acerto = 89.3\n",
      "Erro de teste 0.40532649916537705 Porcentagem de acerto do teste= 80.36\n",
      "It =  210 Erro = 0.3369149978920751 Porcentagem de acerto = 89.4\n",
      "Erro de teste 0.40513580298817253 Porcentagem de acerto do teste= 80.34\n",
      "It =  220 Erro = 0.32563289516480054 Porcentagem de acerto = 89.6\n",
      "Erro de teste 0.4024568670746291 Porcentagem de acerto do teste= 80.67\n",
      "It =  230 Erro = 0.3216240810982547 Porcentagem de acerto = 89.4\n",
      "Erro de teste 0.4044180953403232 Porcentagem de acerto do teste= 80.91\n",
      "It =  240 Erro = 0.33204256328037474 Porcentagem de acerto = 89.8\n",
      "Erro de teste 0.41500554261839573 Porcentagem de acerto do teste= 80.91\n",
      "It =  250 Erro = 0.32028129394593247 Porcentagem de acerto = 89.9\n",
      "Erro de teste 0.3952367114551454 Porcentagem de acerto do teste= 81.82\n",
      "It =  260 Erro = 0.32182160738371113 Porcentagem de acerto = 89.9\n",
      "Erro de teste 0.39033685917081823 Porcentagem de acerto do teste= 82.04\n",
      "It =  270 Erro = 0.31255786709805655 Porcentagem de acerto = 90.6\n",
      "Erro de teste 0.38205869750722415 Porcentagem de acerto do teste= 81.94\n",
      "It =  280 Erro = 0.3171699098813096 Porcentagem de acerto = 90.0\n",
      "Erro de teste 0.39638066669306476 Porcentagem de acerto do teste= 82.08\n",
      "It =  290 Erro = 0.3015594672494926 Porcentagem de acerto = 90.8\n",
      "Erro de teste 0.39992509260350195 Porcentagem de acerto do teste= 81.81\n"
     ]
    }
   ],
   "source": [
    "import numpy, sys\n",
    "np.random.seed(1)\n",
    "def relu(x):\n",
    "    return (x >= 0) * x \n",
    "                        \n",
    "\n",
    "def relu2deriv(output):\n",
    "    return output >= 0 \n",
    "alpha, iterations, hidden_size = (0.005, 300, 100)\n",
    "pixels_per_image, num_labels = (784, 10)\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0,0)\n",
    "    for i in range(len(images)):\n",
    "        layer_0 = images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "        error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
    "        layer_2_delta = (labels[i:i+1] - layer_2)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "        layer_1_delta *= dropout_mask\n",
    "\n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "\n",
    "    if(j%10 == 0):\n",
    "        test_error = 0.0\n",
    "        test_correct_cnt = 0\n",
    "\n",
    "        for i in range(len(test_images)):\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "            layer_2 = np.dot(layer_1, weights_1_2)\n",
    "\n",
    "            test_error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
    "            test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "        print(\"It = \",j,end=' ')\n",
    "        print('Erro =', error/len(images), \"Porcentagem de acerto =\",100*correct_cnt/float(len(images)))\n",
    "        print(\"Erro de teste\",test_error/len(test_images), \"Porcentagem de acerto do teste=\",100*test_correct_cnt/float(len(test_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2AU_UjmtqyT"
   },
   "source": [
    "# Acelerando a velocidade de treinamento e a taxa de convergência com o treinamento em grupos\n",
    "\n",
    "- E se ao invés de atualizarmos o peso para cada entrada atualizassemos o peso a cada n entradas? Isso diminuiria a quantidade de multiplicações que faríamos e aumentaria a taxa de convergência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "s4w_qGHUtNmJ",
    "outputId": "9f1b5d05-a51c-4c79-ccec-92cd9127043c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It =  0 Erro = 3.5755481131452553 Porcentagem de acerto = 20.9\n",
      "Erro de teste 0.7962961057679061 Porcentagem de acerto do teste= 44.43\n",
      "It =  10 Erro = 0.5394688368988976 Porcentagem de acerto = 77.9\n",
      "Erro de teste 0.5162940224335857 Porcentagem de acerto do teste= 77.3\n",
      "It =  20 Erro = 0.46584474321460156 Porcentagem de acerto = 83.0\n",
      "Erro de teste 0.4683346342955877 Porcentagem de acerto do teste= 80.54\n",
      "It =  30 Erro = 0.41187551802045647 Porcentagem de acerto = 86.1\n",
      "Erro de teste 0.4433257737592483 Porcentagem de acerto do teste= 81.34\n",
      "It =  40 Erro = 0.39618488733428564 Porcentagem de acerto = 87.6\n",
      "Erro de teste 0.42448624650989 Porcentagem de acerto do teste= 82.39\n",
      "It =  50 Erro = 0.3843393405669388 Porcentagem de acerto = 85.0\n",
      "Erro de teste 0.412727528544892 Porcentagem de acerto do teste= 83.07\n",
      "It =  60 Erro = 0.36272677805158016 Porcentagem de acerto = 88.3\n",
      "Erro de teste 0.4034576429240668 Porcentagem de acerto do teste= 83.22\n",
      "It =  70 Erro = 0.36657029307695516 Porcentagem de acerto = 86.8\n",
      "Erro de teste 0.4001141535155645 Porcentagem de acerto do teste= 83.36\n",
      "It =  80 Erro = 0.36463504306929106 Porcentagem de acerto = 88.3\n",
      "Erro de teste 0.39735810100154206 Porcentagem de acerto do teste= 83.73\n",
      "It =  90 Erro = 0.3479194674112941 Porcentagem de acerto = 88.9\n",
      "Erro de teste 0.3966044243090795 Porcentagem de acerto do teste= 83.66\n",
      "It =  100 Erro = 0.3434016047815413 Porcentagem de acerto = 88.3\n",
      "Erro de teste 0.395897684135039 Porcentagem de acerto do teste= 83.49\n",
      "It =  110 Erro = 0.3482229861457555 Porcentagem de acerto = 88.3\n",
      "Erro de teste 0.3991534051863999 Porcentagem de acerto do teste= 83.22\n",
      "It =  120 Erro = 0.33721002765425107 Porcentagem de acerto = 89.6\n",
      "Erro de teste 0.40280037503779387 Porcentagem de acerto do teste= 83.3\n",
      "It =  130 Erro = 0.3399376020560776 Porcentagem de acerto = 89.1\n",
      "Erro de teste 0.40404203279253154 Porcentagem de acerto do teste= 83.44\n",
      "It =  140 Erro = 0.3294349362619445 Porcentagem de acerto = 90.1\n",
      "Erro de teste 0.4019861639634098 Porcentagem de acerto do teste= 83.26\n",
      "It =  150 Erro = 0.33417803923299666 Porcentagem de acerto = 89.1\n",
      "Erro de teste 0.40173886506196055 Porcentagem de acerto do teste= 83.25\n",
      "It =  160 Erro = 0.330843604021507 Porcentagem de acerto = 90.7\n",
      "Erro de teste 0.4017838007693478 Porcentagem de acerto do teste= 83.26\n",
      "It =  170 Erro = 0.33601742969531245 Porcentagem de acerto = 89.1\n",
      "Erro de teste 0.4042191061478671 Porcentagem de acerto do teste= 83.55\n",
      "It =  180 Erro = 0.32968374535322464 Porcentagem de acerto = 89.7\n",
      "Erro de teste 0.4067452738500564 Porcentagem de acerto do teste= 83.43\n",
      "It =  190 Erro = 0.3294968223370935 Porcentagem de acerto = 89.9\n",
      "Erro de teste 0.40658474125244687 Porcentagem de acerto do teste= 83.51\n",
      "It =  200 Erro = 0.32064158684124466 Porcentagem de acerto = 90.6\n",
      "Erro de teste 0.4068634854132224 Porcentagem de acerto do teste= 83.54\n",
      "It =  210 Erro = 0.3136027144575971 Porcentagem de acerto = 91.2\n",
      "Erro de teste 0.4083544298457823 Porcentagem de acerto do teste= 83.24\n",
      "It =  220 Erro = 0.32456718634260856 Porcentagem de acerto = 90.8\n",
      "Erro de teste 0.40836680725044827 Porcentagem de acerto do teste= 83.0\n",
      "It =  230 Erro = 0.3179902995939575 Porcentagem de acerto = 90.7\n",
      "Erro de teste 0.40967300350402164 Porcentagem de acerto do teste= 83.2\n",
      "It =  240 Erro = 0.3186507639471916 Porcentagem de acerto = 91.2\n",
      "Erro de teste 0.41055647039757426 Porcentagem de acerto do teste= 83.11\n",
      "It =  250 Erro = 0.31410640955487856 Porcentagem de acerto = 89.7\n",
      "Erro de teste 0.4108191789282879 Porcentagem de acerto do teste= 82.85\n",
      "It =  260 Erro = 0.3103753749775841 Porcentagem de acerto = 90.6\n",
      "Erro de teste 0.40956354322803157 Porcentagem de acerto do teste= 83.21\n",
      "It =  270 Erro = 0.32231120999191964 Porcentagem de acerto = 90.4\n",
      "Erro de teste 0.41143040627532684 Porcentagem de acerto do teste= 83.23\n",
      "It =  280 Erro = 0.3124344807461572 Porcentagem de acerto = 90.0\n",
      "Erro de teste 0.4104086711663801 Porcentagem de acerto do teste= 83.34\n",
      "It =  290 Erro = 0.3050339216801162 Porcentagem de acerto = 90.1\n",
      "Erro de teste 0.4117336233938586 Porcentagem de acerto do teste= 83.31\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "def relu(x):\n",
    "    return (x >= 0) * x \n",
    "\n",
    "def relu2deriv(output):\n",
    "    return output >= 0 \n",
    "\n",
    "batch_size = 100\n",
    "alpha, iterations = (0.001, 300)\n",
    "pixels_per_image, num_labels, hidden_size = (784, 10, 360)\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,10)) - 0.1\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    for i in range(int(len(images) / batch_size)):\n",
    "        batch_start, batch_end = ((i * batch_size),((i+1)*batch_size))\n",
    "\n",
    "        layer_0 = images[batch_start:batch_end]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        dropout_mask = np.random.randint(2,size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "        error += np.sum((labels[batch_start:batch_end] - layer_2) ** 2)\n",
    "        layer_2_delta = (labels[batch_start:batch_end]-layer_2)/batch_size\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)* relu2deriv(layer_1)\n",
    "        layer_1_delta *= dropout_mask\n",
    "        delta_1_2= layer_1.T.dot(layer_2_delta)\n",
    "        delta_0_1 = layer_0.T.dot(layer_1_delta)\n",
    "        for k in range(batch_size):\n",
    "            correct_cnt += int(np.argmax(layer_2[k:k+1]) == np.argmax(labels[batch_start+k:batch_start+k+1]))\n",
    "            weights_1_2 += alpha * delta_1_2\n",
    "            weights_0_1 += alpha * delta_0_1\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "            \n",
    "    if(j%10 == 0):\n",
    "        test_error = 0.0\n",
    "        test_correct_cnt = 0\n",
    "\n",
    "        for i in range(len(test_images)):\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "            layer_2 = np.dot(layer_1, weights_1_2)\n",
    "\n",
    "            test_error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
    "            test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "        print(\"It = \",j,end=' ')\n",
    "        print('Erro =', error/len(images), \"Porcentagem de acerto =\",100*correct_cnt/float(len(images)))\n",
    "        print(\"Erro de teste\",test_error/len(test_images), \"Porcentagem de acerto do teste=\",100*test_correct_cnt/float(len(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "lpiTEFWbuWLg",
    "outputId": "9e8aa480-5a32-4954-95b3-6bc677df069e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro = 0.32528020011901265 Porcentagem de acerto = 91.1\n",
      "Erro de teste 0.4117336233938586 Porcentagem de acerto do teste= 83.31\n"
     ]
    }
   ],
   "source": [
    "print('Erro =', error/len(images), \"Porcentagem de acerto =\",100*correct_cnt/float(len(images)))\n",
    "print(\"Erro de teste\",test_error/len(test_images), \"Porcentagem de acerto do teste=\",100*test_correct_cnt/float(len(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwt5fOuO5EHi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Workshop Redes Neurais.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
